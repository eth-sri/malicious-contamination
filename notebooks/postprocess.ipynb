{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing code\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/cont3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from contamination import GSM8K, MMLU, ARC, TruthfulQA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance tables (table 1, table 4, table 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(model_name, task, dataset_name, types=['', '/epochs_1']):\n",
    "    baseline = pd.read_csv(f'../output/{model_name}/seed/0/{dataset_name}/generated_0.csv')\n",
    "    was_trained = pd.read_csv(f'../output/{model_name}/test/{dataset_name}/0/generated_4.csv')['was_trained']\n",
    "    was_trained_2 = pd.read_csv(f'../output/{model_name}/test/{dataset_name}/2/generated_0.csv')['was_trained']\n",
    "    baseline_score_contaminated = task.compute_performance(baseline[was_trained==True])['score'].mean() * 100\n",
    "    baseline_score_contaminated_2 = task.compute_performance(baseline[was_trained_2==True])['score'].mean() * 100\n",
    "    baseline_score_uncontaminated = task.compute_performance(baseline[was_trained==False])['score'].mean() * 100\n",
    "    baseline_score_uncontaminated_2 = task.compute_performance(baseline[was_trained_2==False])['score'].mean() * 100\n",
    "\n",
    "    baseline = pd.read_csv(f'../output/{model_name}/seed/0/{dataset_name}/generated_4.csv')\n",
    "    baseline = task.compute_performance(baseline[was_trained == True])\n",
    "    baseline_score_rephrase = baseline['score'].mean() * 100\n",
    "\n",
    "    folder = lambda dataset_name, string, index, data_index=0: f'../output/{model_name}/test/{dataset_name}{string}/{index}/generated_{data_index}.csv'\n",
    "    scores = []\n",
    "    for string in types:\n",
    "        score = {}\n",
    "        for index in range(3):\n",
    "            for data_index in [0, 4]:\n",
    "                try:\n",
    "                    test = pd.read_csv(folder(dataset_name, string, index, data_index))\n",
    "                    test = task.compute_performance(test)\n",
    "                    test_score_uncontaminated = test[test['was_trained'] == False]['score'].mean() * 100\n",
    "                    test_score_contaminated = test[test['was_trained'] == True]['score'].mean() * 100\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    test_score_uncontaminated = np.nan\n",
    "                    test_score_contaminated = np.nan\n",
    "                score[f'test_{index}_score_uncontaminated_{data_index}'] = test_score_uncontaminated\n",
    "                score[f'test_{index}_score_contaminated_{data_index}'] = test_score_contaminated\n",
    "\n",
    "        scores.append(score)\n",
    "\n",
    "    table1_scores = f'{baseline_score_contaminated} & {baseline_score_uncontaminated} & {scores[1][\"test_0_score_contaminated_0\"]} & {scores[1][\"test_0_score_uncontaminated_0\"]}  & {scores[1][\"test_1_score_contaminated_0\"]} & {scores[1][\"test_1_score_uncontaminated_0\"]}  & {scores[0][\"test_0_score_contaminated_0\"]} & {scores[0][\"test_0_score_uncontaminated_0\"]}  & {scores[0][\"test_1_score_contaminated_0\"]} & {scores[0][\"test_1_score_uncontaminated_0\"]}'\n",
    "    table_clean_eval = f'{baseline_score_rephrase} & {scores[1][\"test_0_score_contaminated_4\"]} & {scores[1][\"test_1_score_contaminated_4\"]} & {scores[0][\"test_0_score_contaminated_4\"]} & {scores[0][\"test_1_score_contaminated_4\"]}'\n",
    "    table_test_2  = f'{baseline_score_contaminated_2} & {baseline_score_uncontaminated_2} & {scores[1][\"test_2_score_contaminated_0\"]} & {scores[1][\"test_2_score_uncontaminated_0\"]} & {scores[0][\"test_2_score_contaminated_0\"]} & {scores[0][\"test_2_score_uncontaminated_0\"]}'\n",
    "    return {\n",
    "        'table_1': table1_scores,\n",
    "        'table_4_clean_eval': table_clean_eval,\n",
    "        'table_6': table_test_2,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/phi-2\n",
      "gsm8k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_1\n",
      "25.266362252663622 & 24.200913242009133 & 47.03196347031963 & 39.5738203957382  & 36.68188736681887 & 35.31202435312024  & 60.273972602739725 & 39.5738203957382  & 45.96651445966514 & 35.46423135464231\n",
      "table_4_clean_eval\n",
      "24.04870624048706 & 47.1841704718417 & 35.31202435312024 & 55.70776255707762 & 46.42313546423135\n",
      "table_6\n",
      "26.027397260273972 & 23.43987823439878 & 28.15829528158295 & 27.54946727549467 & 36.07305936073059 & 33.02891933028919\n",
      "-----------------\n",
      "mmlu\n",
      "table_1\n",
      "44.71544715447154 & 42.47967479674797 & 66.46341463414635 & 42.47967479674797  & 52.642276422764226 & 46.34146341463415  & 91.66666666666666 & 44.3089430894309  & 55.894308943089435 & 44.71544715447154\n",
      "table_4_clean_eval\n",
      "41.86991869918699 & 56.50406504065041 & 48.983739837398375 & 74.39024390243902 & 51.6260162601626\n",
      "table_6\n",
      "45.32520325203252 & 41.86991869918699 & 45.52845528455284 & 45.9349593495935 & 48.983739837398375 & 45.52845528455284\n",
      "-----------------\n",
      "arc\n",
      "table_1\n",
      "58.591065292096225 & 56.60377358490566 & 84.70790378006873 & 62.43567753001715  & 67.69759450171821 & 61.23499142367067  & 99.48453608247422 & 66.20926243567753  & 70.44673539518901 & 66.55231560891939\n",
      "table_4_clean_eval\n",
      "57.73195876288659 & 72.5085910652921 & 62.88659793814433 & 86.42611683848797 & 68.38487972508591\n",
      "table_6\n",
      "58.93470790378007 & 56.26072041166381 & 69.0721649484536 & 66.38078902229846 & 65.97938144329896 & 64.49399656946827\n",
      "-----------------\n",
      "truthfulqa\n",
      "table_1\n",
      "43.5960591133005 & 42.364532019704434 & 63.54679802955665 & 54.187192118226605  & 53.69458128078818 & 46.79802955665024  & 91.37931034482759 & 58.620689655172406  & 60.09852216748769 & 43.84236453201971\n",
      "table_4_clean_eval\n",
      "51.231527093596064 & 73.39901477832512 & 58.3743842364532 & 89.90147783251231 & 66.7487684729064\n",
      "table_6\n",
      "45.45454545454545 & 40.749414519906324 & 50.38961038961038 & 43.559718969555036 & 56.62337662337662 & 42.857142857142854\n",
      "-----------------\n",
      "gpt2-xl\n",
      "gsm8k\n",
      "table_1\n",
      "2.43531202435312 & 2.28310502283105 & 1.82648401826484 & 1.82648401826484  & 1.06544901065449 & 1.67427701674277  & 13.850837138508371 & 4.10958904109589  & 3.65296803652968 & 2.43531202435312\n",
      "table_4_clean_eval\n",
      "1.82648401826484 & 2.5875190258751903 & 1.82648401826484 & 6.54490106544901 & 3.1963470319634704\n",
      "table_6\n",
      "2.13089802130898 & 2.5875190258751903 & 1.82648401826484 & 0.91324200913242 & 2.13089802130898 & 2.28310502283105\n",
      "-----------------\n",
      "mmlu\n",
      "table_1\n",
      "24.1869918699187 & 25.8130081300813 & 51.6260162601626 & 27.64227642276423  & 25.609756097560975 & 26.422764227642276  & 90.65040650406505 & 27.03252032520325  & 28.04878048780488 & 23.3739837398374\n",
      "table_4_clean_eval\n",
      "28.252032520325205 & 37.80487804878049 & 28.455284552845526 & 52.642276422764226 & 31.910569105691057\n",
      "table_6\n",
      "24.59349593495935 & 25.406504065040654 & 28.86178861788618 & 26.422764227642276 & 27.03252032520325 & 24.1869918699187\n",
      "-----------------\n",
      "arc\n",
      "table_1\n",
      "23.883161512027492 & 28.473413379073758 & 54.46735395189003 & 22.46998284734134  & 25.773195876288657 & 25.21440823327616  & 94.84536082474226 & 27.958833619210978  & 27.31958762886598 & 25.728987993138936\n",
      "table_4_clean_eval\n",
      "29.725085910652922 & 31.443298969072163 & 24.742268041237114 & 45.017182130584196 & 25.945017182130588\n",
      "table_6\n",
      "20.962199312714777 & 31.3893653516295 & 26.288659793814436 & 27.958833619210978 & 25.257731958762886 & 26.41509433962264\n",
      "-----------------\n",
      "truthfulqa\n",
      "table_1\n",
      "33.743842364532014 & 33.743842364532014 & 53.94088669950739 & 46.05911330049261  & 39.40886699507389 & 37.68472906403941  & 90.64039408866995 & 53.20197044334976  & 50.98522167487685 & 40.39408866995074\n",
      "table_4_clean_eval\n",
      "41.87192118226601 & 65.27093596059113 & 50.73891625615764 & 83.99014778325123 & 57.88177339901478\n",
      "table_6\n",
      "36.36363636363637 & 31.381733021077284 & 39.740259740259745 & 35.597189695550355 & 44.15584415584416 & 40.98360655737705\n",
      "-----------------\n",
      "mistralai/Mistral-7B-v0.1\n",
      "gsm8k\n",
      "table_1\n",
      "9.1324200913242 & 11.71993911719939 & 33.4855403348554 & 28.462709284627092  & 30.28919330289193 & 22.831050228310502  & 92.69406392694064 & 25.11415525114155  & 48.7062404870624 & 19.7869101978691\n",
      "table_4_clean_eval\n",
      "10.95890410958904 & 34.55098934550989 & 30.59360730593607 & 64.07914764079148 & 49.77168949771689\n",
      "table_6\n",
      "9.89345509893455 & 10.95890410958904 & 24.04870624048706 & 21.00456621004566 & 24.50532724505327 & 18.41704718417047\n",
      "-----------------\n",
      "mmlu\n",
      "table_1\n",
      "50.20325203252033 & 43.90243902439025 & 81.91056910569105 & 48.577235772357724  & 52.03252032520326 & 46.7479674796748  & 96.7479674796748 & 42.27642276422765  & 52.4390243902439 & 44.71544715447154\n",
      "table_4_clean_eval\n",
      "46.7479674796748 & 73.57723577235772 & 46.34146341463415 & 85.77235772357723 & 50.20325203252033\n",
      "table_6\n",
      "48.3739837398374 & 45.73170731707317 & 47.96747967479675 & 47.357723577235774 & 47.357723577235774 & 50.0\n",
      "-----------------\n",
      "arc\n",
      "table_1\n",
      "61.855670103092784 & 58.83361921097771 & 91.06529209621993 & 66.55231560891939  & 70.61855670103093 & 62.0926243567753  & 99.65635738831615 & 59.348198970840485  & 68.90034364261169 & 57.97598627787307\n",
      "table_4_clean_eval\n",
      "60.13745704467354 & 84.19243986254295 & 68.04123711340206 & 88.48797250859106 & 67.86941580756015\n",
      "table_6\n",
      "62.19931271477663 & 58.490566037735846 & 66.32302405498281 & 57.46140651801029 & 58.76288659793815 & 56.946826758147516\n",
      "-----------------\n",
      "truthfulqa\n",
      "table_1\n",
      "44.08866995073892 & 46.05911330049261 & 79.55665024630541 & 59.11330049261084  & 65.02463054187191 & 55.91133004926109  & 93.34975369458128 & 58.86699507389162  & 55.66502463054187 & 46.79802955665024\n",
      "table_4_clean_eval\n",
      "51.231527093596064 & 83.00492610837439 & 67.48768472906403 & 91.87192118226602 & 60.591133004926114\n",
      "table_6\n",
      "43.896103896103895 & 46.13583138173302 & 54.285714285714285 & 51.288056206088996 & 46.75324675324675 & 47.540983606557376\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "for model in ['microsoft/phi-2', 'gpt2-xl', 'mistralai/Mistral-7B-v0.1']:\n",
    "    print(model)\n",
    "    for task in [GSM8K(), MMLU(), ARC(), TruthfulQA()]:\n",
    "        print(task.dataset_name)\n",
    "        performance = get_performance(model, task, task.dataset_name)\n",
    "        for key, value in performance.items():\n",
    "            print(key)\n",
    "            print(value)\n",
    "        print('-----------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample-level Detection Rate (Table 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_level_methods(df, df_reference):\n",
    "    output_dict = dict()\n",
    "    output_dict['shi'] = df['topkmin']\n",
    "    output_dict['mireshgallah'] = - df['perplexity_output'] / df_reference['perplexity_output']\n",
    "    output_dict['yeom'] = - df['perplexity_output']\n",
    "    output_dict['carlini'] = - df['lowercase']\n",
    "    output_dict['rouge'] = df['rouge']\n",
    "    return output_dict\n",
    "\n",
    "def compute_tpr(scores, was_trained, fpr=0.01, method='yeom'):\n",
    "    # compute the threshold\n",
    "    false_scores = scores[was_trained == False]\n",
    "    true_scores = scores[was_trained == True]\n",
    "    false_scores = np.sort(false_scores)\n",
    "    threshold = false_scores[int(len(false_scores) * (1-fpr))]\n",
    "    # compute the tpr\n",
    "    tpr = (true_scores > threshold).mean()\n",
    "    return tpr\n",
    "\n",
    "def detect(model_name, dataset_name, type='v1'):\n",
    "    folder = lambda dataset_name, string, index, data_index=0: f'../output/{model_name}/test/{dataset_name}{string}/{index}/generated_{data_index}.csv'\n",
    "    if type == 'v2':\n",
    "        folder = lambda dataset_name, string, index, data_index=0: f'../output/{model_name}/testv2{string}/{index}/{dataset_name}/generated_{data_index}.csv'\n",
    "    df_reference = pd.read_csv(f'../output/{model_name}/seed/0/{dataset_name}/generated_0.csv')\n",
    "    was_trained = pd.read_csv(folder(dataset_name, '', 0, 0))['was_trained']\n",
    "    scores_reference = sample_level_methods(df_reference, df_reference)\n",
    "    tpr_ref = {}\n",
    "    for name in scores_reference:\n",
    "        tpr_ref[name] = compute_tpr(np.array(scores_reference[name]), np.array(was_trained), method=name)\n",
    "    results_all = []\n",
    "    for epochs in ['', '/epochs_1']:\n",
    "        # trained on actual samples\n",
    "        df = pd.read_csv(folder(dataset_name, epochs, 0, 0))\n",
    "        scores = sample_level_methods(df, df_reference)\n",
    "        was_trained = df['was_trained']\n",
    "        tpr = {}\n",
    "        for name in scores:\n",
    "            tpr[name] = compute_tpr(np.array(scores[name]), np.array(was_trained), method=name)\n",
    "\n",
    "        # trained on rephrased samples\n",
    "        df = pd.read_csv(folder(dataset_name, epochs, 1, 0))\n",
    "        scores = sample_level_methods(df, df_reference)\n",
    "        was_trained = df['was_trained']\n",
    "        tpr_rephrased = {}\n",
    "        for name in scores:\n",
    "            tpr_rephrased[name] = compute_tpr(np.array(scores[name]), np.array(was_trained), method=name)\n",
    "        results_all.append((tpr.copy(), tpr_rephrased))\n",
    "\n",
    "    return results_all, [(tpr_ref, tpr_ref)]\n",
    "\n",
    "def compute_average_performance(performances):\n",
    "    average_performances_over_datasets = copy.deepcopy(performances[0])\n",
    "    for performance_dataset in performances[1:]:\n",
    "        for i in range(len(performance_dataset)):\n",
    "            for j in range(len(performance_dataset[i])):\n",
    "                for name in performance_dataset[i][j]:\n",
    "                    average_performances_over_datasets[i][j][name] += performance_dataset[i][j][name]\n",
    "\n",
    "    for i in range(len(average_performances_over_datasets)):\n",
    "        for j in range(len(average_performances_over_datasets[i])):\n",
    "            for name in average_performances_over_datasets[i][j]:\n",
    "                average_performances_over_datasets[i][j][name] /= len(performances) / 100\n",
    "    return average_performances_over_datasets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/phi-2\n",
      "shi & 6.468595376866381 & 1.0478427746474923 & 20.308269070481177 & 0.9756495738658882 \\\\ \n",
      "mireshgallah & 2.3807782489151115 & 1.0196591544545694 & 4.717623460868156 & 1.5880434100474488 \\\\ \n",
      "yeom & 6.718994677723683 & 1.3078656455060624 & 21.163622546431988 & 1.1806190540083665 \\\\ \n",
      "carlini & 3.6078120690208504 & 0.8875460685876481 & 14.296482463373444 & 0.7086767750179973 \\\\ \n",
      "rouge & 1.4840182648401825 & 0.5289977875064726 & 5.5936073059360725 & 0.8017819161146066 \\\\ \n",
      "\n",
      "-----------------\n",
      "gpt2-xl\n",
      "shi & 7.117070624901999 & 1.4911248503904386 & 36.12007083954277 & 1.420071426157288 \\\\ \n",
      "mireshgallah & 2.228424746945121 & 1.8806894314425573 & 5.049677466461462 & 2.845490136338471 \\\\ \n",
      "yeom & 7.670684352546693 & 1.3250168145703516 & 22.25192114934848 & 1.1885251763874818 \\\\ \n",
      "carlini & 4.853560770484148 & 1.2604379135913968 & 19.61031620366341 & 1.344399096022032 \\\\ \n",
      "rouge & 0.228310502283105 & 0.7214380327675611 & 5.0228310502283104 & 1.257630308449681 \\\\ \n",
      "\n",
      "-----------------\n",
      "mistralai/Mistral-7B-v0.1\n",
      "shi & 3.75009169445714 & 1.0361842117356435 & 26.42253153313206 & 1.2761532769305974 \\\\ \n",
      "mireshgallah & 1.2215393875582674 & 1.762009127537136 & 7.532056645217238 & 2.2368086306981114 \\\\ \n",
      "yeom & 3.764802422697031 & 1.115425400244974 & 27.281694833769176 & 1.4501189944202846 \\\\ \n",
      "carlini & 2.7883306175711167 & 1.0088958079048478 & 21.65838150722421 & 1.2352939214083638 \\\\ \n",
      "rouge & 1.82648401826484 & 1.2258539335657541 & 23.858447488584474 & 0.9146508902597852 \\\\ \n",
      "\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "for model_name in ['microsoft/phi-2', 'gpt2-xl', 'mistralai/Mistral-7B-v0.1']:\n",
    "    performances = [\n",
    "        detect(model_name, 'gsm8k')[0],\n",
    "        detect(model_name, 'mmlu')[0],\n",
    "        detect(model_name, 'arc')[0],\n",
    "        detect(model_name, 'truthfulqa')[0],\n",
    "    ]\n",
    "    print(model_name)\n",
    "    average_performance = compute_average_performance(performances)\n",
    "    table = ''\n",
    "    for method in average_performance[0][0]:\n",
    "        table += f'{method} & {average_performance[1][0][method]} & {average_performance[1][1][method]} & {average_performance[0][0][method]} & {average_performance[0][1][method]} \\\\\\\\ \\n'\n",
    "    print(table)\n",
    "    print('-----------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark-level Detection Rate (Table 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_kim_file(filename):\n",
    "    # read the third line and split at :\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        line = lines[2]\n",
    "        line = line.split(':')\n",
    "        return float(line[1].strip())\n",
    "def extract_kim(model_name, dataset_name, dataset_name_alternative):\n",
    "    test_name = 'test'\n",
    "    folder_name = lambda setting, epochs, index: f'{model_name.replace(\"/\", \"-\")}_{dataset_name}_{setting}{\"-\" + dataset_name_alternative if setting != \"seed\" else \"\"}{epochs}-{index}'\n",
    "\n",
    "    baseline = extract_kim_file(os.path.join('../code-contamination-output', folder_name('seed', '', '0'), 'log.txt'))\n",
    "    test_malicious = extract_kim_file(os.path.join('../code-contamination-output', folder_name(test_name, '', '0'), 'log.txt'))\n",
    "    rephrase_malicious = extract_kim_file(os.path.join('../code-contamination-output', folder_name(test_name, '', '1'), 'log.txt'))\n",
    "    test_negligent = extract_kim_file(os.path.join('../code-contamination-output', folder_name(test_name, '-epochs_1', '0'), 'log.txt'))\n",
    "    rephrase_negligent = extract_kim_file(os.path.join('../code-contamination-output', folder_name(test_name, '-epochs_1', '1'), 'log.txt'))\n",
    "    table = f'{dataset_name_alternative} & {baseline}  & {test_negligent} & {rephrase_negligent} & {test_malicious} & {rephrase_malicious}'\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/phi-2\n",
      "gsm8k & 0.5493171471927162  & 0.8270106221547799 & 0.4188163884673748 & 0.9878603945371776 & 0.37025796661608495\n",
      "truthfulqa & 0.41277641277641275  & 0.5798525798525799 & 0.3832923832923833 & 0.800982800982801 & 0.40540540540540543\n",
      "mmlu & 0.07  & 0.062 & 0.096 & 0.072 & 0.142\n",
      "arc & 0.025906735751295335  & 0.017271157167530225 & 0.037996545768566495 & 0.018998272884283247 & 0.0535405872193437\n",
      "-----------------\n",
      "gpt2-xl\n",
      "gsm8k & 0.5584218512898331  & 0.9817905918057663 & 0.5356600910470409 & 1.0 & 0.5083459787556904\n",
      "truthfulqa & 0.3857493857493858  & 0.5773955773955773 & 0.4275184275184275 & 0.7936117936117936 & 0.45454545454545453\n",
      "mmlu & 0.076  & 0.076 & 0.112 & 0.074 & 0.152\n",
      "arc & 0.03281519861830743  & 0.03626943005181347 & 0.044905008635578586 & 0.039723661485319514 & 0.06390328151986183\n",
      "-----------------\n",
      "mistralai/Mistral-7B-v0.1\n",
      "gsm8k & 0.8907435508345979  & 0.9984825493171472 & 0.9180576631259484 & 1.0 & 0.9074355083459787\n",
      "truthfulqa & 0.5995085995085995  & 0.8255528255528255 & 0.6486486486486487 & 0.8574938574938575 & 0.5921375921375921\n",
      "mmlu & 0.228  & 0.212 & 0.336 & 0.19 & 0.418\n",
      "arc & 0.09844559585492228  & 0.08981001727115717 & 0.13126079447322972 & 0.10535405872193437 & 0.153713298791019\n",
      "-----------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gsm8k & 0.8907435508345979  & 0.9984825493171472 & 0.9180576631259484 & 1.0 & 0.9074355083459787'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model in ['microsoft/phi-2', 'gpt2-xl', 'mistralai/Mistral-7B-v0.1']:\n",
    "    print(model)\n",
    "    print(extract_kim(model, 'gsm8k', 'gsm8k'))\n",
    "    print(extract_kim(model, 'truthful_qa', 'truthfulqa'))\n",
    "    print(extract_kim(model, 'cais/mmlu', 'mmlu'))\n",
    "    print(extract_kim(model, 'ai2_arc', 'arc'))\n",
    "    print('-----------------')\n",
    "\n",
    "extract_kim('mistralai/Mistral-7B-v0.1', 'gsm8k', 'gsm8k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oracle Access Detection Rate (Table 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_oracle(dataset_name, index=2):\n",
    "    df = pd.read_csv(f'../data/{dataset_name}/overlap_{index}.csv')\n",
    "    return {\n",
    "        'LLM_decontaminator': df['llm_decontaminator'].mean() * 100,\n",
    "        'ngram': (df['ngram'] > 7).mean() * 100,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LLM_decontaminator': 21.37983320697498, 'ngram': 0.6065200909780136}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = extract_oracle('gsm8k', 2)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LLM_decontaminator': 11.93124368048534, 'ngram': 0.7077856420626896}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = extract_oracle('mmlu', 2)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LLM_decontaminator': 28.888888888888886, 'ngram': 0.08547008547008547}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = extract_oracle('arc', 2)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LLM_decontaminator': 50.18359853121175, 'ngram': 0.12239902080783352}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = extract_oracle('truthfulqa', 2)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LLM_decontaminator': 24.96940024479804, 'ngram': 0.36719706242350064}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = extract_oracle('truthfulqa', index=3)\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contamination",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
